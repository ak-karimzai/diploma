\part*{ВВЕДЕНИЕ}

Аудио дипфейки относятся к тем группам аудио-файлов, которые изготовленные методами глубокими нейронными сетями, которые изучают движения звуко-записей до такой степени, что они могут воспроизводить реалистично звучащий поддельный звук. Обычно их используют для имитации голосов людей, хотя иногда они могут быть забавными, такими методами можно злоупотреблять для распространения дезинформации, которая может привести к пагубным последствиям, некоторые из способов с помощью которых могут использоваться методы дипфейки, включают онлайн-травлю, влияние на политические движения и выдачу себя за людей.


Синтетический или фейковый контент существует уже много лет, но контент, созданный с помощью нейронных сетей, то есть дипфейк, существует всего несколько лет. В то время как фотографии и видео, синтезированные с помощью искусственного интеллекта, получили большое внимание, синтетические человеческие голоса также претерпели значительные изменения, достигнув беспрецедентного качества и эффективности. Однако растущий реализм и доступность синтетических человеческих голосов также таят в себе значительные риски. В то время как методы обнаружения изображений и видео, синтезированных с помощью нейронных сетей, были тщательно изучены, методы обнаружения синтетических человеческих голосов получили меньше внимания и недостаточно развиты. 

В данной научной-исследовательской работе рассмотрим следующие задачи:

\begin{enumerate}
    \item Понятие цифровое аудио;
    \item Процесс преобразование аналоговый голоса в цифровой и
обратно;
    \item Понятие Синтезированное аудио и известны подходы генерации синтетического звука;
    \item Классификация и обзор известных методов обнаружения синтезирование звука.
\end{enumerate}


\addcontentsline{toc}{part}{\textbf{ВВЕДЕНИЕ}}