\chapter{Синтезирование голос}

Под термином "Синтезирование голоса" обычно понимается любой аудио-сигнал, важные характеристики которого были изменены при помощи технологий нейронных сетей, сохраняя при этом воспринимаемую естественность. Ранее проведенные исследования в основном выделяли пять видов дипфейкового звука:

\begin{enumerate}
    \item преобразование текста в речь;
    \item преобразование голоса; 
    \item подделка эмоций;
    \item подделка сцен;
    \item частично подделка.
\end{enumerate}

также в таблице (\ref{table::audio-class}), проведено классификация аудио дипфейков по способу генерации, где в первой столбце таблице представлены поддельные типы дипфейков, во второй столбце - поддельные черты, в третей столбце - поддельные продолжительности то есть частично или полностью синтезирован, в четвертом столбце - с помощью нейронной сети указывается что применяемый метод реализован ли с помощью нейронных сетей.

\section{Преобразование текста в речь}

Преобразование текста в речь (TTS) представляет собой широко применяемую технологию, ориентированную на синтез четкой и естественной речи из произвольного текста с использованием моделей, основанных на методах машинного обучения. Современные модели TTS в основном используют глубокие нейронные сети для генерации реалистичной речи, которая максимально приближена к человеческой.\\

Системы TTS обычно включают в себя два основных модуля: модуль анализа текста и модуль генерации речевых сигналов. Модуль анализа текста разбирает входной текст, определяя тон, интонацию и другие лингвистические аспекты, необходимые для правильной передачи смысла. Затем модуль генерации речевых сигналов создает звуковую последовательность, соответствующую заданному тексту.

\section{Преобразование голоса} 

Преобразование голоса (VC) \cite{wu2015spoofing}, или клонирование голоса в цифровой форме, фокусируется на изменении звучания речи одного говорящего, подражая тембру и просодии другого говорящего, при этом сохраняя содержание оригинального высказывания. Процесс введения в систему VC обычно включает в себя использование естественных высказываний данного говорящего как входных данных.\\

Существует несколько основных подходов к технологиям VC \cite{sisman2020overview}, включая статистический параметрический, частотное искажение и выбор единиц измерения. В частности, статистическая параметрическая модель включает в себя вокодер, аналогичный тому, который используется в статистических параметрических системах синтеза речи (TTS).
\section{Подделка эмоций}


Подделка эмоций \cite{zhao2022emofake}, также известная как модификация эмоционального тонуса, представляет собой технологию, направленную на изменение акустических характеристик звука с целью создания впечатления изменения эмоционального состояния говорящего. Эта методика фокусируется на манипуляции параметрами, такими как тембр, интонация и темп речи, сохраняя при этом остальные аспекты звуковой информации, такие как личность говорящего и содержание высказывания.

\section{Подделка сцен}

Модификация сцены звучания, более известная как подделка сцены \cite{yi2022scenefake}, представляет собой метод, направленный на сопоставление акустической обстановки оригинального высказывания с другой звуковой сценой, используя технологии улучшения речи. В этом процессе сохраняются как личность говорящего, так и содержание высказывания, при этом происходит изменение окружающей аудиообстановки.

\section{Частично подделка}

Частичная подделка \cite{yi2021half}, также известная как модификация части высказывания, представляет собой технику, прицельно изменяющую всего лишь несколько слов в оригинальном высказывании. Этот метод осуществляется путем манипулирования исходными аудиоклипами с использованием подлинных или созданных синтезом звуковых фрагментов. Однако при этом ключевым аспектом является сохранение неизменной личности говорящего.

\begin{table}[H]
	\centering
	\setlength{\tabcolsep}{8pt} % Adjust column spacing
	\renewcommand{\arraystretch}{1.3} % Adjust row spacing
    \caption{Класификации аудио дипфейков по способу генерации}\label{tab:class}
    \captionsetup{justification=raggedright,singlelinecheck=false}
    \begin{tabular}{|p{4cm}|p{3cm}|p{3cm}|p{3cm}|}	
        \hline
		\thead{Поддельный тип} & \thead{Поддельная черта} & \thead{Поддельная продолжительность}  & \thead{С помощью нейронной сети}  \\ 
		\hline
		Преобразование  текста в речь    & Личность спикера, Речевое содержание  & полностью	  	 &  да  \\
		\hline
		Преобразование голоса   & Личность спикера & полностью  &  да \\
		\hline
		Подделка эмоций & эмоция спикера 	& полностью  &  да \\
		\hline
		Подделка сцен  & Акустическая сцена & полностью  &  да \\
		\hline
		Частично подделка  & Речевое содержание 	& частично  &  да \\
		\hline
    \end{tabular}
    \label{table::audio-class}
\end{table}

\chapter{Отличительные признаки аудио для изучения}

Извлечение признаков представляет собой ключевой модуль классификатора аудио-дипфейков. Основной целью этого процесса является изучение характерных особенностей путем выделения акустических артефактов из речевых сигналов, которые могут свидетельствовать о наличии поддельных атак. Большое количество исследований подчеркнуло важность определения полезных признаков для эффективного обнаружения дипфейков.

В данной области уделено значительное внимание выявлению полезных функций, способных обнаруживать характерные аспекты поддельных атак. Признаки, использованные в проведенных исследованиях, условно могут быть разделены на три основные категории \cite{sahidullah2015comparison}: 

\begin{itemize}
    \item Спектральные характеристики;
    \item Просодические характеристики;
    \item Глубокие характеристики.
\end{itemize}

\section{Спектральные характеристики}

Спектральные характеристики в анализе звука относятся к характеристикам, которые отражают распределение энергии по различным частотам в сигнале. Эти характеристики вычисляются с использованием математических преобразований, таких как быстрое преобразование Фурье (FFT), и имеют критическое значение для извлечения существенной информации из аудиосигналов для различных применений. Спектральные характеристики могут быть классифицированы на краткосрочные и долгосрочные в зависимости от временного масштаба, в течение которого они вычисляются.

\subsection{Кратковременные спектральные характеристики}

Кратковременные спектральные характеристики, извлеченные из коротких кадров обычно длительностью 20-30 мс, описывают кратковременную спектральную огибающую, которая включает в себя акустический коррелят тембра голоса. Кратковременные спектральные характеристики вычисляются, главным образом, путем применения кратковременного преобразования Фурье (STFT) к речевому сигналу \cite{xiao2015spoofing}. При предположении, что речевой сигнал x(t) квазистационарен в течение короткого периода, STFT формулируется следующим образом:


\begin{equation}
    X(t, \omega) = |X(t, \omega)| e^{j\phi(\omega)}
\end{equation}

где \(|X(t, \omega)|\), это спектр магнитуд а \(\phi(\omega)\) представляет собой фазовый спектр в кадре t и частотный диапазон \(\omega\). Спектр мощности определяется как \(|X(t, \omega)|^2\).

Кратковременные спектральные характеристики в основном включают кратковременные характеристики, основанные на магнитуде и фазе. Обычно несколько характеристик, базирующихся на магнитуде, напрямую производятся из спектра магнитуды, но большинство из них вычисляются из спектра мощности. Характеристики, основанные на фазе, извлекаются из фазового спектра.

% Спектр магнитуды представляет собой график амплитуд сигнала в зависимости от его частоты, тогда как спектр мощности включает в себя квадрат амплитуд, отражающий распределение энергии. Кратковременные характеристики, основанные на магнитуде, могут включать в себя параметры, такие как частоты формант, амплитудные спектральные величины и мел-частотные кепстральные коэффициенты (MFCC).

\subsection{Долгосрочные спектральные характеристики}

Кратковременные спектральные признаки не очень хорошо передают временные характеристики траекторий речевых признаков из-за того, что они вычисляются покадрово \cite{wu2013synthetic}. Поэтому были предложены долгосрочные спектральные характеристики для получения информации на более широких временных интервалах из речевых сигналов, и исследования показали, что они имеют решающее значение для обнаружения поддельной речи.

Долгосрочные спектральные характеристики охватывают более продолжительные временные участки речевых сигналов и могут лучше отражать долгосрочные изменения в акустических свойствах речи. Это позволяет системе обнаружения более эффективно анализировать речевые траектории и выявлять особенности, связанные с поддельной речью. Такие характеристики могут включать в себя долгосрочные форманты, изменения в спектральной энергии на протяжении времени и другие параметры, охватывающие более широкие аспекты речевого сигнала \cite{das2019long}.

\section{Просодические характеристики}

Просодия относится к несегментарной информации в речевых сигналах, включая ударение на слоге, интонационные паттерны, темп речи и ритм \cite{kinnunen2010overview}. В отличие от кратковременных спектральных характеристик с короткой продолжительностью, обычно составляющей 20-30 мс, просодические особенности охватывают более длинные сегменты, такие как фоны, слоги, слова, высказывания и т.д. Важные просодические параметры включают основную частоту (F0), длительность, распределение энергии, скорость разговора и т.д. Предыдущие исследования \cite{kinnunen2010overview} по обнаружению поддельного звука в основном рассматривали три основные просодические характеристики:

\begin{itemize}
    \item Основная частота (F0): Показатель высоты голоса, который варьируется в зависимости от интонации и эмоционального состояния говорящего;
    \item Длительность: Временной параметр, отражающий продолжительность звуковых сегментов, таких как слоги и слова, в речевом потоке;
    \item Распределение энергии: Характеризует энергетические аспекты речи и может отражать эмфатическое выделение или особенности интонации.
\end{itemize}

Эти просодические характеристики могут быть использованы для выделения особенностей в произношении, что делает их важными для обнаружения поддельного звука, где подделка может влиять на натуральные просодические паттерны голоса. Однако они менее чувствительны к канальным эффектам по сравнению со спектральными функциями \cite{wu2015spoofing}. Они могут предоставлять дополнительную информацию к спектральным функциям для повышения эффективности обнаружения поддельного звука.

\section{Глубокие характеристики}

Упомянутые выше спектральные характеристики и просодические характеристики представляют собой большую часть ручных функций с сильными и желательными репрезентативными способностями. Однако их конструирование подвержено предвзятостям из-за ограничений представлений, внесенных человеческими разработчиками \cite{zeghidour2021leaf}. Таким образом, глубокие функции вдохновлены для заполнения этого пробела. Глубокие функции изучаются с использованием глубоких нейронных сетей, которые условно можно разделить на три категории: обучаемые спектральные функции, контролируемые функции встраивания и самоконтролируемые функции встраивания.

На рисунке (\ref{fig:audio-classification}) представлено, класификации аудио по признаками для обучение: 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.9\linewidth]{images/classification-of-audio.png}
	\caption{Классификации аудио по признаками}
	\label{fig:audio-classification}
\end{figure}


\chapter{Система обнаружения поддельного звука}

\section{Постановка задачи}

Основной задачей системы обнаружения поддельного звука (аудио дипфейк) является процесс выявления поддельного звука в речевом потоке. В качестве входных данных используются звуковые сигналы, а на выходе представляются результаты классификации.

Система в основном состоит из двух частей: модуля извлечения признаков для параметризации речевого сигнала и модуля классификации для определения, является ли он естественным или синтетическим.


\section{Модуль извлечения признаков}

Модуль извлечения признаков должен извлекать соответствующую информацию из речевого сигнала, отражающую артефакты, связанные с процессом преобразования или синтеза. В основном, на этом этапе в большинстве случаев извлекаются спектральные характеристики.

Самые популярные спектральные характеристики, используемые в системе обнаружения синтезированного звука, являются кепстральные коэффициенты мел-частоты (MFCC) и линейные частотные кепстральные коэффициенты (LFCC).

MFCC \cite{vergin1999generalized} представляют собой замкнутую огибающую спектра мощности, проявляющую характеристики человеческого голоса и речевого тракта. Эти коэффициенты характеризуют кепстр Мел-частоты, который известен как "спектр спектра" и необходим для определения периодических компонентов сигнала во временной области. Процесс извлечения MFCC состоит из нескольких математических преобразований сигнала из временной области в частотную область. Это включает в себя преобразование Фурье и дискретные косинусные преобразования для получения логарифмического представления спектра \cite{rao2017speech}. Генерация векторов MFCC состоит из следующих этапов:

\begin{itemize}
    \item Предварительное усиление входного сигнала для удаления нежелательных или высоких частот.
    \item Формирование и обработка сигнала в окне, цель которого состоит в том, чтобы разделить сигнал на последовательность коротких перекрывающихся кадров, чтобы гарантировать их стационарность. При этом стационарный сигнал отражает истинные статистические и временные характеристики. Формирование окон часто выполняется с использованием прямоугольных окон, таких как окно Хэмминга, которое скрывает потенциал искаженных сегментов, обнаруженных на границах окон, путем их сглаживания.
    \item Применение преобразования Фурье сигналов для их преобразования из временной области в частотную область, чтобы представить их с точки зрения их статистических и спектральных характеристик.
    \item Применение банков фильтров "мел фильтры" для генерации кадров в шкале мел-частот.
    \item Вычисление логарифмического значения величины мощности, полученной с помощью Мел-фильтров.
    \item Вычисление спектра результатов, полученных на предыдущем шаге, путем применения дискретного косинусного преобразования (ДКП), которое приводит к кепстральным коэффициентам: \begin{equation} c(n) = \sum_{0}^{M - 1} \log_{10}(s(m)) \cos(\frac{\pi n (m - 0.5)}{M})\end{equation}, где \(n \in \{0, 1, \dots C-1\}\), \(c(n)\) представляет собой кепстральные коэффициенты, а \(C\) представляет собой количество MFCC.
\end{itemize}

Процесс получения LFCC аналогичный MFCC, за исключением того, что он использует расположенный набор фильтров на линейной частотной шкале с равномерным разделением между фильтрами.

\section{Модель класификации}

В системах, используемых для обнаружения поддельного звука, важным фактором являются параметрические характеристики аудио для изучения, и внутренний классификатор играет ключевую роль в глубоком распознавании аудио. Целью является изучение высокоуровневого представления функций входного интерфейса и моделирование превосходных возможностей обнаружения. Внутренние классификаторы, которые часто используются для обнаружения аудио-дипфейков, в основном делятся на две категории:
\begin{itemize}
    \item Статистические методы;
    \item С использованием глубоких нейронных сетей.
\end{itemize}

\subsection{Статистические методы обнаружения Аудио Дипфейк}

Под термином "статистические методы" в статьях часто подразумевают алгоритмы машинного обучения, которые изучают характеристики аудио для решения задачи обнаружения аудиодипфейков. Для решения данной задачи используются алгоритмы бинарной классификации.

В связи с этим для обнаружения фальшивой речи было использовано множество классических подходов к классификации паттернов. Самые популярные методы обнаружения аудиодипфейков с применением машинного обучения включают:

\begin{itemize}
    \item Машина опорных векторов (англ. Support Vector Machine);
    \item Гауссовые модели смеси (англ. Gaussian mixture model).
\end{itemize}

\subsubsection{Машина опорных векторов (SVM)}

SVM - это контролируемый метод обучения, который основывается в основном на двух предположениях \cite{hamza2022deepfake}:
\begin{enumerate}
    \item Преобразование данных в многомерное пространство может свести сложные проблемы классификации со сложными поверхностями принятия решений к более мелким проблемам, которые могут быть решены путем их линейного разделения;
    \item Только обучающие шаблоны вблизи поверхности принятия решений обеспечивают наиболее чувствительную детали для классификации.
\end{enumerate}

Так как проблема обнаружения аудиодипфейков представляет собой бинарную классификацию с линейно разделяемыми векторами \(x_{i} \in \mathbb{R}^{n}\), в качестве поверхности принятия решения, используемой для классификации паттерна как принадлежащего к одному из двух классов, используется гиперплоскость \(H_{0}\). Если \(x\) это случайный вектор \(n \times \mathbb{R}\), тогда мы определяем:

\begin{equation}
    f_{(x)} = w.x + b
\end{equation}

В формуле \(.\) это скалярное произведение, набор всех \(x\)-векторов, удовлетворяющих уравнению \(f_{(x)} = 0\), обозначается как \(H_{0}\). Предполагая две гиперплоскости, \(H_{1}\) и \(H_{2}\), расстояние между ними называется их границей, которую можно представить следующим образом:

\begin{equation}
    \begin{cases}
        H_{1} = \{x \in \mathbb{R}^{n} | f_{(x)} > 0\} \\
        H_{2} = \{x \in \mathbb{R}^{n} | f_{(x)} < 0\}
    \end{cases}
\end{equation}

Гиперплоскость решения \(H_{0}\) зависит от векторов, ближайших к двум параллельным гиперплоскостям, называемым опорными векторами. Запас должен быть максимальным, чтобы получить классификатор, который не очень адаптирован к обучающим данным.

На рисунке (\ref{fig:support-vector-machine}) представлено, машина опорных векторов: 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.4\linewidth]{images/support-vector-machine.png}
	\caption{Машина опорных векторов (SVM)}
	\label{fig:support-vector-machine}
\end{figure}

В многих статьях по классификации аудио-дипфейков где классификатор реализован на базе SVM. SVM отлично справляется с четким разделением выборок и эффективен в средах с высокой размерностью. SVM использует подмножество точек обучения в функции принятия решения, что делает его эффективным с точки зрения использования памяти.

% \subsubsection*{Методы с применением SVM}
% 
% В статей [110] и [68], используют машина опорных векторов в качестве классификатора, в статей [110] предполагают, что классификаторы SVM по своей сути устойчивы к атакам с искусственным подменой сигналов. Однако очень трудно определить точную природу атак с подменой в практических сценариях.
% В статей [68] предложили одноклассовый классификатор SVM, обученный только использованию подлинных высказываний для классификации реальных и поддельных голосов, который хорошо подходит для неизвестных атак с использованием подделки.

\subsubsection{Гауссовые моделей смеси (GMM)}

Модель смеси гауссовых распределений (GMM), как следует из названия, представляет собой смесь нескольких гауссовских распределений. Речевые признаки представлены в виде векторов в n-мерном пространстве. Распределение этих векторов признаков представлено смесью гауссовских плотностей. 

Для \(n\)-мерного вектора признаков \(x\) функция плотности смеси для класса \(s\) с параметром модели \(\lambda^{s}\) определяется как \cite{JOTHILAKSHMI2016301}:

\begin{equation}
    p(x | \lambda^{s}) = \sum_{i = 1}^{\mathcal{M}} \alpha^{s}_{i} f_{i}^{s}(x)
\end{equation}

Функция плотности смеси представляет собой взвешенную линейную комбинацию \(\mathcal{M}\) унимодальных гауссовских плотностей компонентов \(f_ {i}^{s}(.)\). Каждая функция гауссовской плотности \(f_{i}^{s}(.)\) параметризуется вектором среднего \(\mu_{i}^{s}\) и ковариационной матрицей \(\Sigma_{i}^{s}\) с использованием:

\begin{equation}
    f_{i}^{s}(x) = \frac{1}{\sqrt{(2\pi)^{n}|\Sigma_{i}^{s}|}} \exp \left(-\frac{1}{2}(x - \mu_{i}^{s})^T \Sigma_{i}^{s}^{-1} (x - \mu_{i}^{s})\right)
\end{equation}

где \(\Sigma_{i}^{s}\) является ковариационной матрицей, а \((\Sigma_{i}^{s})^{-1}\) называется обратной ковариационной матрицей.
% \subsubsection*{Методы с применением GMM}
% 
% В статей [32] и [114], в качестве классификатора используется GMM. в статей [32] используется в качестве классификатора человеческих и синтезированных голосов.
% в статей [114], предложят метод, который определяет разницу между реальной и преобразованной речью, используя логарифмическое отношение правдоподобия, основанное на модели GMM для реальной и преобразованной речи.

\subsection{Методы с применением глубоких нейронных сетей}


Классификаторы современных систем обнаружения аудиодипфейков в основном основаны на методах глубокого обучения, которые значительно превосходят классификаторы, основанные на SVM и GMM, благодаря их мощным возможностям моделирования \cite{godoy2015using}.

Каждый аудиосигнал может быть представлен на двумерном графике, построенном с использованием математических расчетов. Обработка аудиозаписей в нейронной сети требует большого объема вычислений для создания системы, способной обнаруживать аудиодипфейки с гораздо меньшими затратами вычислений. Это достигается путем преобразования аудиозаписей в изображения звуковых объектов и последующего получения значений массива в числовом формате, наилучшим образом подходящих для передачи в качестве входных данных в нейронную сеть.

Существует конференция, где ученые из разных стран представляют свои решения по созданию и обнаружению синтезированного звука, она называется ASVSpoof и проводится каждые три года \cite{yamagishi2021asvspoof}. В основном все решения, которые предлагают, основаны на методах глубокого обучения. Рассмотрим два метода, которые показали меньшую ошибку при классификации.
\begin{enumerate}
    \item Сверточная нейронная сеть (CNN);
    \item Остаточная нейронная сеть (RNN).
\end{enumerate}

\subsubsection{Общая логика работы нейронных сетей}

Первоначальное развитие этих сетей берет свое начало в работе Фрэнка Розенблатта о персептронах и начинается с определения нейрона \cite{DOU2023484}. Математически нейрон - это нелинейность, применяемая к аффинной функции. Входные характеристики \(x = (x_1, x_2, . . . , x_n)\) передаются через аффинную функцию, составленную с нелинейностью \(\phi\):

\begin{equation}
    T(x) = \phi\left(\sum_{i} W_{i} \ast x_{i} + b\right) = \phi(W \ast x + b)
\end{equation}

с заданными весами \(W\) и смещением \(b\). Схематично это представлено на рисунке (\ref{fig:neuron}). Типичной нелинейностью, или функцией активации, является сигмоидная форма, определяемая как:

\begin{equation}
    \phi(x) = \frac{1}{1 + e^{-x}}
\end{equation}

Функция активации не обязательно должна быть только сигмоидной; она выбирается в зависимости от задачи, которую необходимо решить с использованием нейронных сетей.

На рисунке (\ref{fig:neuron}) представлено, cхематическая версия нейрона: 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\linewidth]{images/neuron.png}
	\caption{Схематическая версия нейрона}
	\label{fig:neuron}
\end{figure}

Нейронную сеть можно смоделировать как набор нейронов, которые соединены в ациклический граф. То есть выходные данные некоторых нейронов становятся входными данными для других нейронов, и циклы, в которых выходные данные нейрона отображаются обратно на более ранний промежуточный вход, запрещены. Обычно такие нейроны организованы в слои нейронов. Такая сеть состоит из входного слоя, одного или нескольких скрытых слоев и выходного слоя. В отличие от скрытых слоев, выходной слой обычно не имеет функции активации.

В зависимости от задачи нейронные сети могут обучаться контролируемым или неконтролируемым способом и соответствено в нейронных сетей появится термин функция потерь, также называемая функцией стоимости или целевой функцией, играет ключевую роль в измерении несоответствия между прогнозируемым выходным сигналом сети и фактическими целевыми значениями. Основная цель на этапе обучения — минимизировать эту функцию потерь, поскольку это повышает точность модели при составлении прогнозов и для того что бы уменьшить потери изпользуется обратное распространение ошибки и так представляется:

\begin{equation}
    \frac{\partial L}{\partial W} = \frac{\partial L}{\partial T} * \frac{\partial T}{\partial Z} * \frac{\partial Z}{\partial W}
\end{equation}

Где \(\frac{\partial L}{\partial W}\) — это градиент функции потерь по весам W.

На рисунке (\ref{fig:neuron-arch}) представлено, трехслойная нейронная сеть с тремя входами и двумя скрытыми слоями: 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\linewidth]{images/neural-arch.png}
	\caption{Трехслойная нейронная сеть с тремя входами и двумя скрытыми слоями}
	\label{fig:neuron-arch}
\end{figure}

\subsubsection{Сверточная нейронная сеть (CNN)}

Сверточные нейронные сети (CNN) представляют собой частный случай нейронных сетей с прямой связью. В отличие от обычных нейронных сетей, слои CNN содержат нейроны, расположенные в нескольких измерениях: в каналах, ширине, высоте и количестве фильтров в простейшем двумерном случае.

Наиболее распространенными строительными блоками, с которыми столкиваются в большинстве архитектур CNN, являются уровень свертки, уровень пула и полностью связанные уровни.

\subsubsection*{Cвертки}

Математическая свертка \((x * w)(a)\) функций \(x\) и \(w\) определяется во всех измерениях как:

\begin{equation}
    (x * w)(a) = \int x(t) * w (t - a) \, da
\end{equation}

где \(a\) находится в \(R^{n}\) для любого \(n \ge 1\), а интеграл заменяется его многомерным вариантом. В терминологии сверточных нейронных сетей \(x\) называется входом, \(w\) называется фильтром или ядром, а выход часто называют активацией или картой признаков.

\subsubsection*{Нелинейности}

Нелинейности необходимы для проектирования нейронных сетей, без них нейронная сеть будет вычислять линейную функцию своих входных данных, что является слишком ограничительным. Выбор нелинейности может оказать большое влияние на скорость обучения нейронной сети. Следовательно, часто после того, как мы получаем результаты из каждой свертки, мы применяем функцию активации.

\subsubsection*{Объединение слоев}

Целью слоя объединения является создание сводной статистики его входных данных и уменьшение пространственных размеров карты объектов. Наиболее распространенной формой является максимальный пул, который использует шаг 2 вместе с размером ядра 2. Это соответствует пространственному разбиению карты объектов на регулярную сетку квадратных или кубических блоков со стороной 2 и взятию максимального или среднего значения по таким блокам для каждого входного объекта.

На рисунке (\ref{fig:max-pool}) представлено, максимальный пул c шагом 2 вместе с размером ядра 2: 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.5\linewidth]{images/max-pooling.png}
	\caption{максимальный пул c шагом 2 вместе с размером ядра 2}
	\label{fig:max-pool}
\end{figure}

\subsubsection*{Полностью связанные слои}

Полностью связанный слой с \(n\) входными измерениями и \(m\) выходными измерениями определяется следующим образом.

Выход слоя определяется параметрами: весовой матрицей \(W \in \mathbb{M}_{m,n}(\mathbb{R})\), имеющей \(m\) строк и \(n\) столбцов, и вектором смещения \(b \in \mathbb{R}^{m}\). Для данного входного вектора \(x \in \mathbb{R}^{n}\), выход полносвязного слоя \(FC\) с функцией активации \newpage \(f\) определяется как:

\begin{equation}
    FC(x) := f(W \cdot x + b) \in \mathbb{R}^{m}
\end{equation}

В приведенной выше формуле \(W \cdot x\) — это произведение матриц, а функция \(f\) применяется покомпонентно.

\subsubsection{Остаточная нейронная сеть (RNN)}

Остаточные нейронные сети состоят из множества остаточных блоков \cite{he2016deep}. Учитывая остаточный блок \(l\) и его входные данные \(x\), выходные данные определяются как:

\begin{equation}
    x_{l + 1} = \sigma(F_{l}(x_{l}) + x_{l})
\end{equation}

В формуле \(F_{l}\) обозначает остаточную функцию, где \(F_{l}(x) = \text{BN}(W_{l,2} \cdot \sigma(\text{BN}(W_{l,1} \cdot x)))\), а \(W_{l,1}\) и \(W_{l,2}\) являются сверточными весовыми матрицами, \(\text{BN}(x)\) обозначает пакетную нормализацию, а \(\sigma(x)\) - функцию активации.

На рисунке (\ref{fig:residual-block}) представлено, остаточный блок: 
\begin{figure}[H]
	\centering
	\includegraphics[width=0.3\linewidth]{images/residual-block.png}
	\caption{Остаточный блок}
	\label{fig:residual-block}
\end{figure}

Однако данная формулировка трудно интерпретируется аналитически, и она не содержит "истинного" соединения с пропуском идентификации из-за конечного компонента функции активации. Вместо этого используется остаточный блок с предварительной активацией \cite{he2016identity}. Учитывая остаточный блок \(l\) и его входной сигнал \(x_{l}\), выходной сигнал теперь определяется как:

\begin{equation}
    x_{l + 1} = \sigma(F_{l}(x_{l}) + x_{l})
\end{equation}

В формуле \(F_{l}\) обозначает остаточную функцию, где \(F_{l}(x) = W_{l,2} \cdot \text{BN}(\sigma(W_{l,1}) \cdot \sigma(\text{BN}(x)))\). Эта формулировка более четко выводится из интуиции, поскольку мы непосредственно добавляем выходные данные слоя к выходным данным следующего слоя.

Рекурсивно, пишется следующим образом:

\begin{equation}
    x_{l + 1} = x_{l} + \sum_{i = l}^{L - 1} F_{i}(x_{i})
\end{equation}

для более глубокого остаточного блока \(L\) и более мелкого остаточного блока \(l\). Эта формулировка поддерживает путь идентификации по всей сети, поэтому теоретически, если более мелкие остаточные блоки сети способны идентифицировать разумное представление, сеть может обойти остальные уровни, используя пропускные соединения.

Мы также можем удалить все остаточные соединения, чтобы сформировать стандартную сеть, где, рассматривая пары сверточных слоев, мы получаем аналогичные уравнения:

\begin{equation}
    x_{l} = F_{l}(x_{l})
\end{equation}

И таким образом, получим:

\begin{equation}
    x_{l} = F_{L - 1}(F_{L - 2}(\ldots F_{1}(x_{1})))
\end{equation}
