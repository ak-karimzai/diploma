@misc{elad2023image,
      title={Image Denoising: The Deep Learning Revolution and Beyond -- A Survey Paper --}, 
      author={Michael Elad and Bahjat Kawar and Gregory Vaksman},
      year={2023},
      eprint={2301.03362},
      archivePrefix={arXiv},
      primaryClass={eess.IV}
}

@article{kong2023comparison,
  title={A Comparison of Image Denoising Methods},
  author={Kong, Zhaoming and Deng, Fangxi and Zhuang, Haomin and Yang, Xiaowei and Yu, Jun and He, Lifang},
  journal={arXiv preprint arXiv:2304.08990},
  year={2023}
}

@article{DOU2023484,
  title = {Understanding neural network through neuron level visualization},
  journal = {Neural Networks},
  volume = {168},
  pages = {484-495},
  year = {2023},
  issn = {0893-6080},
  doi = {https://doi.org/10.1016/j.neunet.2023.09.030},
  url = {https://www.sciencedirect.com/science/article/pii/S0893608023005269},
  author = {Hui Dou and Furao Shen and Jian Zhao and Xinyu Mu},
  keywords = {Interpretability, Neural network, Visualization},
  abstract = {Neurons are the fundamental units of neural networks. In this paper, we propose a method for explaining neural networks by visualizing the learning process of neurons. For a trained neural network, the proposed method obtains the features learned by each neuron and displays the features in a human-understandable form. The features learned by different neurons are combined to analyze the working mechanism of different neural network models. The method is applicable to neural networks without requiring any changes to the architectures of the models. In this study, we apply the proposed method to both Fully Connected Networks (FCNs) and Convolutional Neural Networks (CNNs) trained using the backpropagation learning algorithm. We conduct experiments on models for image classification tasks to demonstrate the effectiveness of the method. Through these experiments, we gain insights into the working mechanisms of various neural network architectures and evaluate neural network interpretability from diverse perspectives.}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part IV 14},
  pages={630--645},
  year={2016},
  organization={Springer}
}

@article{patrick2022capsule,
  title={Capsule networks--a survey},
  author={Patrick, Mensah Kwabena and Adekoya, Adebayo Felix and Mighty, Ayidzoe Abra and Edward, Baagyire Y},
  journal={Journal of King Saud University-computer and information sciences},
  volume={34},
  number={1},
  pages={1295--1310},
  year={2022},
  publisher={Elsevier}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@misc{zhang2022deep,
      title={Deep Image Deblurring: A Survey}, 
      author={Kaihao Zhang and Wenqi Ren and Wenhan Luo and Wei-Sheng Lai and Bjorn Stenger and Ming-Hsuan Yang and Hongdong Li},
      year={2022},
      eprint={2201.10700},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}

@inproceedings{gao2019dynamic,
  title={Dynamic scene deblurring with parameter selective sharing and nested skip connections},
  author={Gao, Hongyun and Tao, Xin and Shen, Xiaoyong and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3848--3856},
  year={2019}
}

@inproceedings{zhang2020deblurring,
  title={Deblurring by realistic blurring},
  author={Zhang, Kaihao and Luo, Wenhan and Zhong, Yiran and Ma, Lin and Stenger, Bjorn and Liu, Wei and Li, Hongdong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2737--2746},
  year={2020}
}

@article{chen2009empirical,
  title={An empirical identification method of Gaussian blur parameter for image deblurring},
  author={Chen, Fen and Ma, Jianglin},
  journal={IEEE Transactions on signal processing},
  volume={57},
  number={7},
  pages={2467--2478},
  year={2009},
  publisher={IEEE}
}

@inproceedings{zhang2019deep,
  title={Deep stacked hierarchical multi-patch network for image deblurring},
  author={Zhang, Hongguang and Dai, Yuchao and Li, Hongdong and Koniusz, Piotr},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5978--5986},
  year={2019}
}

@inproceedings{suin2020spatially,
  title={Spatially-attentive patch-hierarchical network for adaptive motion deblurring},
  author={Suin, Maitreya and Purohit, Kuldeep and Rajagopalan, AN},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3606--3615},
  year={2020}
}

@inproceedings{zamir2021multi,
  title={Multi-stage progressive image restoration},
  author={Zamir, Syed Waqas and Arora, Aditya and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={14821--14831},
  year={2021}
}

@inproceedings{hore2010image,
  title={Image quality metrics: PSNR vs. SSIM},
  author={Hore, Alain and Ziou, Djemel},
  booktitle={2010 20th international conference on pattern recognition},
  pages={2366--2369},
  year={2010},
  organization={IEEE}
}

@article{wang2004image,
  title={Image quality assessment: from error visibility to structural similarity},
  author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal={IEEE transactions on image processing},
  volume={13},
  number={4},
  pages={600--612},
  year={2004},
  publisher={IEEE}
}

@misc{kupyn2018deblurgan,
  title={DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks}, 
  author={Orest Kupyn and Volodymyr Budzan and Mykola Mykhailych and Dmytro Mishkin and Jiri Matas},
  year={2018},
  eprint={1711.07064},
  archivePrefix={arXiv},
  primaryClass={cs.CV}
}

@InProceedings{unet2015,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}
