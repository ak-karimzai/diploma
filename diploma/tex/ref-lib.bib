@misc{shen2018deep,
      title={Deep Semantic Face Deblurring}, 
      author={Ziyi Shen and Wei-Sheng Lai and Tingfa Xu and Jan Kautz and Ming-Hsuan Yang},
      year={2018}
}

@inproceedings{NIPS2009_3dd48ab3,
 author = {Krishnan, Dilip and Fergus, Rob},
 booktitle = {Advances in Neural Information Processing Systems},
 editor = {Y. Bengio and D. Schuurmans and J. Lafferty and C. Williams and A. Culotta},
 pages = {},
 publisher = {Curran Associates, Inc.},
 title = {Fast Image Deconvolution using Hyper-Laplacian Priors},
 volume = {22},
 year = {2009}
}

@article{Lian2023,
  title = {An image deblurring method using improved U-Net model based on multilayer fusion and attention mechanism},
  author = {Lian, Zuozheng and Wang, Haizhen},
  journal = {Scientific Reports},
  volume = {13},
  number = {1},
  pages = {21402},
  year = {2023},
  month = {12},
  day = {4},
  issn = {2045-2322},
  abstract = {The investigation of image deblurring techniques in dynamic scenes represents a prominent area of research. Recently, deep learning technology has gained extensive traction within the field of image deblurring methodologies. However, such methods often suffer from limited inherent interconnections across various hierarchical levels, resulting in inadequate receptive fields and suboptimal deblurring outcomes. In U-Net, a more adaptable approach is employed, integrating diverse levels of features effectively. Such design not only significantly reduces the number of parameters but also maintains an acceptable accuracy range. Based on such advantages, an improved U-Net model for enhancing the image deblurring effect was proposed in the present study. Firstly, the model structure was designed, incorporating two key components: the MLFF (multilayer feature fusion) module and the DMRFAB (dense multi-receptive field attention block). The aim of these modules is to improve the feature extraction ability. The MLFF module facilitates the integration of feature information across various layers, while the DMRFAB module, enriched with an attention mechanism, extracts crucial and intricate image details, thereby enhancing the overall information extraction process. Finally, in combination with fast Fourier transform, the FRLF (Frequency Reconstruction Loss Function) was proposed. The FRLF obtains the frequency value of the image by reducing the frequency difference. The present experiment results reveal that the proposed method exhibited higher-quality visual effects. Specifically, for the GoPro dataset, the PSNR (peak signal-to-noise ratio) reached 31.53, while the SSIM (structural similarity index) attained a value of 0.948. Additionally, for the Real Blur dataset, the PSNR achieved 31.32, accompanied by an SSIM score of 0.934.}
}

@inproceedings{sun2010,
author = {Sun, Shao Jie and Wu, Qiong and Li, Guo Hui},
title = {Image Deblurring Algorithm for Overlap-Blurred Image},
year = {2010},
month = {10},
volume = {439},
pages = {493--498},
booktitle = {Advanced Measurement and Test X},
series = {Key Engineering Materials},
publisher = {Trans Tech Publications Ltd},
keywords = {Coded-Shutter Model, Overlap-Blurred Image, Blind Image Deconvolution, Criminal Detection Forensics},
abstract = {Overlap-blur is caused by the relative movement of high speed between the camera and the object during the exposure process, which is one of the most common phenomenons of image degradation during the criminal detection forensics work. Based on the analysis of the overlap-blurred imageâ€™s characteristic, a coded-shutter model is proposed to approximate the nature of overlap-blur. As the first attempt, using the coded-shutter model, an image deblurring algorithm is designed for the restoration of the overlap-blurred images. The experiment results show the validity and rationality of the coded-shutter model for deblurring the overlap-blurred images. When tested on the real overlap-blurred photographs, the proposed algorithm can restore the information of interest in the blurred images better, which demonstrates the higher practical value of the algorithm.}
}

@misc{elad2023image,
      title={Image Denoising: The Deep Learning Revolution and Beyond -- A Survey Paper --}, 
      author={Michael Elad and Bahjat Kawar and Gregory Vaksman},
      year={2023}
}

@article{kong2023comparison,
  title={A Comparison of Image Denoising Methods},
  author={Kong, Zhaoming and Deng, Fangxi and Zhuang, Haomin and Yang, Xiaowei and Yu, Jun and He, Lifang},
  journal={arXiv preprint arXiv:2304.08990},
  year={2023}
}

@article{kirkland2010bilinear,
  title={Bilinear interpolation},
  author={Kirkland, Earl J},
  journal={Advanced computing in electron microscopy},
  pages={261--263},
  year={2010},
  publisher={Springer}
}

@article{DOU2023484,
  title = {Understanding neural network through neuron level visualization},
  journal = {Neural Networks},
  volume = {168},
  pages = {484-495},
  year = {2023},
  issn = {0893-6080},
  author = {Hui Dou and Furao Shen and Jian Zhao and Xinyu Mu},
  keywords = {Interpretability, Neural network, Visualization},
  abstract = {Neurons are the fundamental units of neural networks. In this paper, we propose a method for explaining neural networks by visualizing the learning process of neurons. For a trained neural network, the proposed method obtains the features learned by each neuron and displays the features in a human-understandable form. The features learned by different neurons are combined to analyze the working mechanism of different neural network models. The method is applicable to neural networks without requiring any changes to the architectures of the models. In this study, we apply the proposed method to both Fully Connected Networks (FCNs) and Convolutional Neural Networks (CNNs) trained using the backpropagation learning algorithm. We conduct experiments on models for image classification tasks to demonstrate the effectiveness of the method. Through these experiments, we gain insights into the working mechanisms of various neural network architectures and evaluate neural network interpretability from diverse perspectives.}
}

@inproceedings{woo2018cbam,
  title={Cbam: Convolutional block attention module},
  author={Woo, Sanghyun and Park, Jongchan and Lee, Joon-Young and Kweon, In So},
  booktitle={Proceedings of the European conference on computer vision (ECCV)},
  pages={3--19},
  year={2018}
}

@inproceedings{he2016deep,
  title={Deep residual learning for image recognition},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={770--778},
  year={2016}
}

@inproceedings{he2016identity,
  title={Identity mappings in deep residual networks},
  author={He, Kaiming and Zhang, Xiangyu and Ren, Shaoqing and Sun, Jian},
  booktitle={Computer Vision--ECCV 2016: 14th European Conference, Amsterdam, The Netherlands, October 11--14, 2016, Proceedings, Part IV 14},
  pages={630--645},
  year={2016},
  organization={Springer}
}

@article{patrick2022capsule,
  title={Capsule networks--a survey},
  author={Patrick, Mensah Kwabena and Adekoya, Adebayo Felix and Mighty, Ayidzoe Abra and Edward, Baagyire Y},
  journal={Journal of King Saud University-computer and information sciences},
  volume={34},
  number={1},
  pages={1295--1310},
  year={2022},
  publisher={Elsevier}
}

@article{lecun2015deep,
  title={Deep learning},
  author={LeCun, Yann and Bengio, Yoshua and Hinton, Geoffrey},
  journal={nature},
  volume={521},
  number={7553},
  pages={436--444},
  year={2015},
  publisher={Nature Publishing Group UK London}
}

@misc{zhang2022deep,
      title={Deep Image Deblurring: A Survey}, 
      author={Kaihao Zhang and Wenqi Ren and Wenhan Luo and Wei-Sheng Lai and Bjorn Stenger and Ming-Hsuan Yang and Hongdong Li},
      year={2022}
}

@inproceedings{gao2019dynamic,
  title={Dynamic scene deblurring with parameter selective sharing and nested skip connections},
  author={Gao, Hongyun and Tao, Xin and Shen, Xiaoyong and Jia, Jiaya},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3848--3856},
  year={2019}
}

@inproceedings{zhang2020deblurring,
  title={Deblurring by realistic blurring},
  author={Zhang, Kaihao and Luo, Wenhan and Zhong, Yiran and Ma, Lin and Stenger, Bjorn and Liu, Wei and Li, Hongdong},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={2737--2746},
  year={2020}
}

@article{chen2009empirical,
  title={An empirical identification method of Gaussian blur parameter for image deblurring},
  author={Chen, Fen and Ma, Jianglin},
  journal={IEEE Transactions on signal processing},
  volume={57},
  number={7},
  pages={2467--2478},
  year={2009},
  publisher={IEEE}
}

@inproceedings{zhang2019deep,
  title={Deep stacked hierarchical multi-patch network for image deblurring},
  author={Zhang, Hongguang and Dai, Yuchao and Li, Hongdong and Koniusz, Piotr},
  booktitle={Proceedings of the IEEE/CVF Conference on Computer Vision and Pattern Recognition},
  pages={5978--5986},
  year={2019}
}

@inproceedings{suin2020spatially,
  title={Spatially-attentive patch-hierarchical network for adaptive motion deblurring},
  author={Suin, Maitreya and Purohit, Kuldeep and Rajagopalan, AN},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={3606--3615},
  year={2020}
}

@inproceedings{zamir2021multi,
  title={Multi-stage progressive image restoration},
  author={Zamir, Syed Waqas and Arora, Aditya and Khan, Salman and Hayat, Munawar and Khan, Fahad Shahbaz and Yang, Ming-Hsuan and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF conference on computer vision and pattern recognition},
  pages={14821--14831},
  year={2021}
}

@article{rajaei2023analysis,
  title={An analysis of multi-stage progressive image restoration network (MPRNet)},
  author={Rajaei, Boshra and Rajaei, Sara and Damavandi, Hossein},
  journal={Image Processing On Line},
  volume={13},
  pages={140--152},
  year={2023}
}

@inproceedings{hore2010image,
  title={Image quality metrics: PSNR vs. SSIM},
  author={Hore, Alain and Ziou, Djemel},
  booktitle={2010 20th international conference on pattern recognition},
  pages={2366--2369},
  year={2010},
  organization={IEEE}
}

@article{wang2004image,
  title={Image quality assessment: from error visibility to structural similarity},
  author={Wang, Zhou and Bovik, Alan C and Sheikh, Hamid R and Simoncelli, Eero P},
  journal={IEEE transactions on image processing},
  volume={13},
  number={4},
  pages={600--612},
  year={2004},
  publisher={IEEE}
}

@misc{kupyn2018deblurgan,
  title={DeblurGAN: Blind Motion Deblurring Using Conditional Adversarial Networks}, 
  author={Orest Kupyn and Volodymyr Budzan and Mykola Mykhailych and Dmytro Mishkin and Jiri Matas},
  year={2018}
}

@InProceedings{unet2015,
author="Ronneberger, Olaf
and Fischer, Philipp
and Brox, Thomas",
editor="Navab, Nassir
and Hornegger, Joachim
and Wells, William M.
and Frangi, Alejandro F.",
title="U-Net: Convolutional Networks for Biomedical Image Segmentation",
booktitle="Medical Image Computing and Computer-Assisted Intervention -- MICCAI 2015",
year="2015",
publisher="Springer International Publishing",
address="Cham",
pages="234--241",
abstract="There is large consent that successful training of deep networks requires many thousand annotated training samples. In this paper, we present a network and training strategy that relies on the strong use of data augmentation to use the available annotated samples more efficiently. The architecture consists of a contracting path to capture context and a symmetric expanding path that enables precise localization. We show that such a network can be trained end-to-end from very few images and outperforms the prior best method (a sliding-window convolutional network) on the ISBI challenge for segmentation of neuronal structures in electron microscopic stacks. Using the same network trained on transmitted light microscopy images (phase contrast and DIC) we won the ISBI cell tracking challenge 2015 in these categories by a large margin. Moreover, the network is fast. Segmentation of a 512x512 image takes less than a second on a recent GPU. The full implementation (based on Caffe) and the trained networks are available at http://lmb.informatik.uni-freiburg.de/people/ronneber/u-net.",
isbn="978-3-319-24574-4"
}

@inproceedings{nah2017deep,
  title={Deep multi-scale convolutional neural network for dynamic scene deblurring},
  author={Nah, Seungjun and Hyun Kim, Tae and Mu Lee, Kyoung},
  booktitle={Proceedings of the IEEE conference on computer vision and pattern recognition},
  pages={3883--3891},
  year={2017}
}

@inproceedings{shen2019human,
  title={Human-aware motion deblurring},
  author={Shen, Ziyi and Wang, Wenguan and Lu, Xiankai and Shen, Jianbing and Ling, Haibin and Xu, Tingfa and Shao, Ling},
  booktitle={Proceedings of the IEEE/CVF International Conference on Computer Vision},
  pages={5572--5581},
  year={2019}
}

@online{python,
    title = {Python Programming Language},
  url     = {https://www.affectiva.com/},
  urldate = {2024-05-20}
}


@online{paszke2019pytorch,
  title={PyTorch: An Imperative Style, High-Performance Deep Learning Library},
  author={Paszke, Adam and Gross, Sam and Massa, Francisco and Lerer, Adam and Bradbury, James and Chanan, Gregory and Killeen, Trevor and Lin, Zeming and Gimelshein, Natalia and Antiga, Luca and Desmaison, Alban and Kopf, Andreas and Yang, Edward and DeVito, Zachary and Raison, Martin and Tejani, Alykhan and Chilamkurthy, Sasank and Steiner, Benoit and Fang, Lu and Bai, Junjie and Chintala, Soumith},
  year={2019},
  urldate = {2024-05-09},
  url={https://pytorch.org/}
}


@online{nvidia2011cuda,
  title={NVIDIA CUDA Software and GPU Parallel Computing Architecture},
  author={NVIDIA Corporation},
  year={2011},
  urldate = {2024-05-09},
  url={https://developer.nvidia.com/cuda-zone}
}

@online{clark2002python,
  title={Python Imaging Library (PIL)},
  author={Clark, Fredrik},
  organization={PythonWare},
  year={2002},
    urldate = {2024-05-09},
  url={https://python-pillow.org/}
}

@online{intel_core_i7_8750h,
  title={Intel Core i7-8750H 2.2 GHz Processor},
  urldate = {2024-05-10},
  url={https://ark.intel.com/content/www/us/en/ark/products/134906/intel-core-i7-8750h-processor-9m-cache-up-to-4-10-ghz.html}
}

@misc{geforce_gtx_1080_ti,
  title={Nvidia GeForce GTX 1080 Ti video card},
    urldate = {2024-05-10},
  url={https://www.nvidia.com/en-us/geforce/products/10series/geforce-gtx-1080-ti/}
}

@misc{ubuntu2004,
    title = {{Ubuntu 20.04 LTS}},
    author = {{Canonical Ltd.}},
   urldate = {2024-05-10},
    url = {https://releases.ubuntu.com/20.04/},
    year = {2020}
}

@inproceedings{rim2020real,
  title={Real-world blur dataset for learning and benchmarking deblurring algorithms},
  author={Rim, Jaesung and Lee, Haeyun and Won, Jucheol and Cho, Sunghyun},
  booktitle={Computer Vision--ECCV 2020: 16th European Conference, Glasgow, UK, August 23--28, 2020, Proceedings, Part XXV 16},
  pages={184--201},
  year={2020},
  organization={Springer}
}